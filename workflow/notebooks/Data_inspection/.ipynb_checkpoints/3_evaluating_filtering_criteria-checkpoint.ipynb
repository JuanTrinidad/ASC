{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0fb73f-e766-4ef5-8fc4-807a80f2ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51ac85ae-7889-4564-9077-38119b1710d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hypothetical OG data\n",
    "df_hypothetical_OG = pd.read_csv('../../report/Ortholog_Group_Full_of_hypotetical_boolean.tsv', sep='\\t')\n",
    "\n",
    "#RBH results\n",
    "df_rbh = pd.read_csv('../../../results/reciprocal_best_hit_TSV/rbh_all_in_one_file.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "#model organims annotation data\n",
    "df_MO_annotation = pd.read_csv('../../../results/Gene_annotation_info_from_uniprot_model_spp.tsv', sep='\\t', low_memory=False, index_col=0)\n",
    "\n",
    "#kinetoplastea annotation data\n",
    "#one structure per row\n",
    "df_kineto_annotation = pd.read_csv('../../protein_data_bases/annotation_info/kinetoplastea_taxid5653_annotation_info_from_uniprot.tsv', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05415382-fca1-4330-880f-42a7e71cfeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8b18b-bdf4-4d92-8cb6-48fd78e1c313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c954f2-12ca-4cb9-8d86-7c56d42029d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54470176-42f7-4cbf-84c8-59a6fe3957a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767d663-075b-42bd-a76b-787f71955395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8754800-52cc-474a-9ec9-94736fda9222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c40399-a01e-45f3-ad03-4634608845e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b429a75f-2f05-4cc5-916b-0374059ee1cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'query_uniprot_accession'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_rbh_k \u001b[38;5;241m=\u001b[39m \u001b[43mdf_rbh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_kineto_annotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_uniprot_accession\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEntry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:10093\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10074\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10075\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10089\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10091\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10094\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10102\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10103\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1179\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m     lk \u001b[38;5;241m=\u001b[39m cast(Hashable, lk)\n\u001b[0;32m-> 1179\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1180\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query_uniprot_accession'"
     ]
    }
   ],
   "source": [
    "df_rbh_k = df_rbh.merge(df_kineto_annotation, left_on='query_uniprot_accession', right_on='Entry', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c49ba80-89d0-46f2-8734-705e6c72410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbh_km = df_rbh_k.merge(df_MO_annotation, left_on='target_uniprot_accession', right_on='Entry', how='left', suffixes=['_kineto', '_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4a1a7-d662-4c28-bb43-cc074dd4a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbh_km = df_rbh_km[~df_rbh_km.spp.isin(['LEIIN', 'TRYCC', 'TRYB2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600cca7-4e86-466f-8bc2-aa7c857ffa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b79c8ca-98b1-457b-b288-877ec8ad7c2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "df_rbh_km[['query','PANTHER_kineto','PANTHER_model']].drop_duplicates('query').dropna()#.to_csv('prueba.tsv', sep='\\t')#.drop_duplicates('query').PANTHER_kineto.nunique()\n",
    "\n",
    "df_rbh_km[['query','Pfam_kineto','Pfam_model']].drop_duplicates('query').dropna()\n",
    "\n",
    "df_rbh_km[['query','Protein families_kineto','Protein families_model']].drop_duplicates('query').dropna()\n",
    "\n",
    "df_rbh_km[['query','EC number_kineto','EC number_model']].drop_duplicates('query').dropna()\n",
    "\n",
    "df_rbh_km[['query','OrthoDB_kineto','OrthoDB_model']].drop_duplicates('query').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba40e8-1ed1-427b-a779-16249e412c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbh_km[['query','PANTHER_kineto','PANTHER_model']].drop_duplicates('query').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3de92-82b9-4ec0-a1f2-aa5d9997bdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c6535-0f9b-4c5a-8d1b-f45642620fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde21b9e-c4d4-42d6-9a3b-6e1459a847b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779f57c-7cf0-4429-b7c8-dde2d45a25ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb8e81-de75-4596-8dd3-fdcefb8a41da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dfb0b-64bd-492f-b61a-d64a0eb35761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703c8b2-f8af-441a-80e5-69efdefb6f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a637977-cfc6-475f-9622-a3cd297d6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in kinetoplastidea data thw best categories are Interprot, Gene Ontology (GO), Gene Ontology IDs, PANTHER, OrthoDB, Pfam, KEGG, Protein families #los GO hay que mirarlos con otra perspectiva sobre todo el orden jerarquico\n",
    "df_rbh_k.notna().sum().sort_values(ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e159a8-dc1d-4854-b6b3-074234e7541f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wich category has more information to use as reference\n",
    "\n",
    "df_rbh_km.notna().sum().sort_values(ascending=False).tail(50)\n",
    "#en el df completo las categorias con mas info son Interprot, PANTHER, KEGG, OrthoDB, Pfam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad30737-ab3b-4bf2-a9a8-5e2698cb15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbh_km[['eggNOG_model', 'eggNOG_kineto']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15672bcb-3c7c-4184-b860-3665b49e5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_kineto_annotation.columns[8:].drop('Reviewed') \n",
    "columns_for_evaluation =  ['EC number', 'Protein families', 'OrthoDB','PANTHER', 'InterPro', 'Pfam', 'eggNOG'] #'KEGG'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd6169-b995-48ba-af27-ba0276bad677",
   "metadata": {},
   "source": [
    "# Evaluation of annotation coincidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5a603-d86d-4552-a5bb-31773aa3d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tengo que revisar el roden de las columnas, es decir, si por ejemplo panther siempre va de mas inclusivo a menos o como hace.\n",
    "\n",
    "#modifing columns\n",
    "\n",
    "def compare_lists(list1, list2):\n",
    "    \n",
    "    list1 = list1.split(';')\n",
    "    list2 = list2.split(';')\n",
    "    \n",
    "    list1 = [x for x in list1 if x != '']\n",
    "    list2 = [x for x in list2 if x != '']\n",
    "    \n",
    "    #sorting\n",
    "    list1.sort()\n",
    "    list2.sort()\n",
    "    \n",
    "    if list1 == list2:\n",
    "        shared_items = 'ALL'\n",
    "        \n",
    "    else:\n",
    "        shared_items = 0\n",
    "        for item in list1:\n",
    "            if item in list2:\n",
    "                shared_items += 1\n",
    "                \n",
    "        if shared_items == 0:\n",
    "            shared_items = 'CERO'\n",
    "        else:\n",
    "            shared_items = '1orMORE'\n",
    "    \n",
    "    \n",
    "    return shared_items\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def column_selection_coincidence_calculation(parameter_list):\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = parameter_list[0]\n",
    "    columna  = parameter_list[1]\n",
    "    \n",
    "    fident = parameter_list[2]\n",
    "    comb0 = parameter_list[3]\n",
    "    comb1 = parameter_list[4]\n",
    "    \n",
    "    \n",
    "    columna_k = columna +'_kineto' #get both columns\n",
    "    columna_m = columna +'_model'\n",
    "    \n",
    "    df = df[(df['fident'] > fident) & (df['COV_query'] > comb0) & (df['COV_target'] > comb1) ]\n",
    "\n",
    "\n",
    "    df = df[[columna_k, columna_m]].dropna() #droping nana values\n",
    "\n",
    "    #print(df_rbh_km.shape)\n",
    "    #print(df.shape)\n",
    "    \n",
    "    series = df.apply(lambda row: compare_lists(row[columna_k], row[columna_m]), axis=1)\n",
    "    \n",
    "    series.name = columna +'_'+ str(fident) +'_'+ str(comb0)+'_'+ str(comb1) \n",
    "    \n",
    "    return series'''\n",
    "\n",
    "\n",
    "\n",
    "def column_selection_coincidence_calculation(df, columna, columna_final):\n",
    "    \n",
    "    \n",
    "    columna_k = columna +'_kineto' #get both columns\n",
    "    columna_m = columna +'_model'\n",
    "    \n",
    "\n",
    "    df = df[[columna_k, columna_m]].dropna() #droping nana values\n",
    "\n",
    "    #print(df_rbh_km.shape)\n",
    "    #print(df.shape)\n",
    "    \n",
    "    series = df.apply(lambda row: compare_lists(row[columna_k], row[columna_m]), axis=1)\n",
    "    \n",
    "    series.name = columna_final\n",
    "    \n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b35025-78e1-41e4-a6e4-b8627ee51d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b0fefe-163e-434d-b9ae-059da46eff1e",
   "metadata": {},
   "source": [
    "d = df_rbh_km[['query','target','PANTHER_kineto','PANTHER_model']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa39fe6-894d-4f3b-9f85-6930cef45b2a",
   "metadata": {},
   "source": [
    "d = column_selection_coincidence_calculation(d, 'PANTHER', 'PANTHER_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db77800-693b-42e2-9064-822a857d36d7",
   "metadata": {},
   "source": [
    "d.PANTHER_final.gt(0).sum()\n",
    "#d.PANTHER_final.eq(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12c73f-da3b-445a-82e3-21bf2f898b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68daa1-b77a-4cba-a08b-dc495a072fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new df for simplification\n",
    "df_looop = df_rbh_km.copy()\n",
    "\n",
    "\n",
    "#dictionary to storage data\n",
    "data_colection = []\n",
    "#number of iterations as index\n",
    "iterations = 0\n",
    "\n",
    "\n",
    "for fident in np.arange(0,.75,0.05):    \n",
    "    fident = round(fident, 3)\n",
    "    print(fident)\n",
    "    \n",
    "    for columna in columns_for_evaluation: #iterating over interesting columns #['PANTHER']:#\n",
    "                \n",
    "        \n",
    "        #for comb in combinations_with_replacement(np.arange(0,1,0.1), 2): #all combination with replacement of coverage values\n",
    "                        \n",
    "        #    comb0 = round(comb[0],2)\n",
    "        #    comb1 = round(comb[1],2)\n",
    "            \n",
    "        for evalue in [1e-30, 1e-20, 1e-15, 1e-10, 1e-5, 1e-2, 1]:\n",
    "\n",
    "\n",
    "\n",
    "            #colname\n",
    "            #columna_final =  columna + '_count_'+ str(fident)+ '_' + str(comb0) +'_'+ str(comb1) + '_' + str(evalue)\n",
    "            columna_final =  columna + '_count_'+ str(fident)+ '_' + str(evalue)\n",
    "\n",
    "            #filtering dataframe with parameters of interest\n",
    "            #df_looop = df_looop[(df_looop['fident'] > fident) & (df_looop['COV_query'] > comb0) & (df_looop['COV_target'] > comb1) & (df_looop['evalue'] < evalue)]\n",
    "            df_looop_filtered = df_looop[(df_looop['fident'] > fident) & (df_looop['evalue'] < evalue)]\n",
    "\n",
    "\n",
    "            #list_parameters.append([df_looop, columna, fident, comb0, comb1])\n",
    "\n",
    "            data_colection.append( column_selection_coincidence_calculation(df_looop_filtered, columna, columna_final) )\n",
    "\n",
    "            #print(columna_final)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ede11-b8ca-4588-b23b-d2a1ac65ef5c",
   "metadata": {},
   "source": [
    "# Same approach only with best hit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fd5b3-48e2-4a33-b597-a9e3f68d2d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new df for simplification\n",
    "\n",
    "#only best hit\n",
    "df_looop = df_looop.sort_values('evalue').drop_duplicates(subset=['query'], keep='first')\n",
    "#dictionary to storage data\n",
    "data_colection_BH = []\n",
    "#number of iterations as index\n",
    "iterations = 0\n",
    "\n",
    "\n",
    "#for exponent in range(0, 22, 2): #creating list of evalues to check\n",
    "#    evalue = 0.1 ** exponent\n",
    "#    print(evalue)\n",
    "    \n",
    "    #filtering pvalue\n",
    "\n",
    "for fident in np.arange(0,.75,0.05):    \n",
    "    fident = round(fident, 3)\n",
    "    print(fident)\n",
    "    \n",
    "    for columna in columns_for_evaluation: #iterating over interesting columns #['PANTHER']:#\n",
    "                \n",
    "        \n",
    "        #for comb in combinations_with_replacement(np.arange(0,1,0.1), 2): #all combination with replacement of coverage values\n",
    "                        \n",
    "        #    comb0 = round(comb[0],2)\n",
    "        #    comb1 = round(comb[1],2)\n",
    "            \n",
    "        for evalue in [1e-30, 1e-20, 1e-15, 1e-10, 1e-5, 1e-2, 1]:\n",
    "\n",
    "\n",
    "\n",
    "            #colname\n",
    "            #columna_final =  columna + '_count_'+ str(fident)+ '_' + str(comb0) +'_'+ str(comb1) + '_' + str(evalue)\n",
    "            columna_final =  columna + '_count_'+ str(fident)+ '_' + str(evalue)\n",
    "\n",
    "            #filtering dataframe with parameters of interest\n",
    "            #df_looop = df_looop[(df_looop['fident'] > fident) & (df_looop['COV_query'] > comb0) & (df_looop['COV_target'] > comb1) & (df_looop['evalue'] < evalue)]\n",
    "            df_looop_filtered = df_looop[(df_looop['fident'] > fident) & (df_looop['evalue'] < evalue)]\n",
    "\n",
    "\n",
    "            #list_parameters.append([df_looop, columna, fident, comb0, comb1])\n",
    "\n",
    "            data_colection_BH.append( column_selection_coincidence_calculation(df_looop_filtered, columna, columna_final) )\n",
    "\n",
    "            #print(columna_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6347f8-f6af-48bd-bd8b-ac245f39a64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c02c50-de2f-41e1-86c1-f5e3f0d9b372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc183c66-c91d-4218-a522-6158e37f5943",
   "metadata": {},
   "source": [
    "# Creating the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17b92c-da49-4635-98bb-7485f321ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_values(df):\n",
    "    \n",
    "    df_gt0 = df.gt(0).sum()\n",
    "    df_eq0 = df.eq(0).sum()\n",
    "    df_NaN = df.isna().sum()\n",
    "    \n",
    "    #aclaracion en este conteo (los tres de abajo) los TP y FP pueden solaparse. Porque estamos contando para c/rbh si es correcto o no. Por ejemplo, si un query tiene 10 rbh correctos y 1 rbh incorrecto va a sumar 1 para cada categoria\n",
    "    #amount of gene TP\n",
    "    df_gt0_nunique_query = df.gt(0).groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #amount of gene FP\n",
    "    df_eq0_nunique_query = df.eq(0).groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #amount of gene NaN\n",
    "    df_NaN_nunique_query = df.isna().groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #column names\n",
    "    df_gt0.name = 'TruePositive'\n",
    "    df_eq0.name = 'FalsePositive'\n",
    "    df_NaN.name = 'NaN'\n",
    "    \n",
    "    df_gt0_nunique_query.name = 'TruePositive_query_count'\n",
    "    df_eq0_nunique_query.name = 'FalsePositive_query_count'\n",
    "    df_NaN_nunique_query.name = 'NaN_query_count'\n",
    "    \n",
    "    \n",
    "    return pd.concat([df_gt0, df_eq0, df_NaN, df_gt0_nunique_query, df_eq0_nunique_query, df_NaN_nunique_query], axis=1)\n",
    "# precision\n",
    "def column_calculations(df, name):\n",
    "    df['sum_TPFP'] = df['TruePositive'] + df['FalsePositive']\n",
    "    df['precision'] = df['TruePositive'] / df['sum_TPFP']\n",
    "    df['TruePositive_x_sum_TPFP'] = df['TruePositive'] * df['precision']\n",
    "    \n",
    "    df.to_csv(name, sep='\\t')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def counting_values(df):\n",
    "    \n",
    "    df_ALL = df.eq('ALL').sum()\n",
    "    df_1orMORE = df.eq('1orMORE').sum()    \n",
    "    df_CERO = df.eq('CERO').sum()\n",
    "    df_NaN = df.isna().sum()\n",
    "    \n",
    "    #aclaracion en este conteo (los tres de abajo) los TP y FP pueden solaparse. Porque estamos contando para c/rbh si es correcto o no. Por ejemplo, si un query tiene 10 rbh correctos y 1 rbh incorrecto va a sumar 1 para cada categoria\n",
    "    #amount of gene TP\n",
    "    df_ALL_nunique_query = df.eq('ALL').groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #amount of gene partial TP\n",
    "    df_1orMORE_nunique_query = df.eq('1orMORE').groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #amount of gene partial FP\n",
    "    df_CERO_nunique_query = df.eq('CERO').groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #amount of gene NaN\n",
    "    df_NaN_nunique_query = df.isna().groupby('query').sum().gt(0).sum()\n",
    "    \n",
    "    #column names\n",
    "    df_ALL.name = 'ALL'\n",
    "    df_1orMORE.name = '1orMORE'\n",
    "    df_CERO.name = 'CERO'\n",
    "    df_NaN.name = 'NaN'\n",
    "    \n",
    "    df_ALL_nunique_query.name = 'ALL_TruePositive_query_count'\n",
    "    df_1orMORE_nunique_query.name = '1orMORE_TruePositive_query_count'\n",
    "    \n",
    "    df_CERO_nunique_query.name = 'CERO_FalsePositive_query_count'\n",
    "    df_NaN_nunique_query.name = 'NaN_query_count'\n",
    "    \n",
    "    \n",
    "    return pd.concat([df_ALL, df_1orMORE,df_CERO, df_NaN, df_ALL_nunique_query, df_1orMORE_nunique_query, df_CERO_nunique_query, df_NaN_nunique_query], axis=1)\n",
    "\n",
    "# precision\n",
    "def column_calculations_modif(df, name):\n",
    "    \n",
    "    df['TruePositive'] = df['ALL'] + df['1orMORE']\n",
    "    \n",
    "    df['sum_TPFP'] = df['TruePositive'] + df['CERO']\n",
    "    df['precision'] = df['TruePositive'] / df['sum_TPFP']\n",
    "    \n",
    "    df['TruePositive_x_sum_TPFP'] = df['TruePositive'] * df['precision']\n",
    "    \n",
    "    df.to_csv(name, sep='\\t')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62719c5-f7e6-4e7d-b967-b57e8ed058eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#concat outputs\n",
    "df_all_rbh = pd.concat(data_colection, axis=1)\n",
    "df_only_BH = pd.concat(data_colection_BH, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b1b1e-6c0b-4e2a-9ffd-54f5f99fcd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb082f87-3f01-4383-8429-db73e1efeb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f0692-0b3c-44e4-8462-d6d3237ad198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding structure info\n",
    "df_all_rbh = df_rbh_km[['query', 'target']].merge(df_all_rbh, left_index=True, right_index=True, how='left')\n",
    "df_only_BH = df_rbh_km[['query', 'target']].merge(df_only_BH, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f9107-a670-47d7-ad05-dc773aab85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to index\n",
    "df_all_rbh = df_all_rbh.set_index(['query', 'target'])\n",
    "df_only_BH = df_only_BH.set_index(['query', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90809243-e016-46eb-97a4-a0c315857ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#smallinf the df\n",
    "#df_all_rbh = df_all_rbh.dropna(how='all')\n",
    "#df_only_BH = df_only_BH.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e490a-6ede-4015-ab26-fbaa18faeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_rbh.eq('ALL').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896cbd7-3585-4e37-a5e3-97f16b60d59d",
   "metadata": {},
   "source": [
    "## appying funtions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e86f12-c1fd-46f3-a17b-99ec556ae288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0 = df_all_rbh.pipe(counting_values).pipe(column_calculations_modif, 'rbh_all_hits_annotationDB_evaluation_TP_FP.tsv')\n",
    "\n",
    "df1 = df_only_BH.pipe(counting_values).pipe(column_calculations_modif, 'rbh_only_best_rbh_hit_annotationDB_evaluation_TP_FP.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb142fe-b2ef-4b4d-a1c0-a2098a693f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e36617-a153-4948-b4f9-aabb92d97259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860526a-c301-46f6-af04-4a0085422bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31421c32-f354-475a-a47b-edfca91c1b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957915a-240d-4c29-9c19-b362d6280d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9656d-9046-440b-9eb9-fc9a3d327609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f136d38-d71b-43bd-b77f-b5d26ced14ae",
   "metadata": {},
   "source": [
    "# CHEKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e0f57-36c1-4dae-8c14-86089b7931a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new df for simplification\n",
    "df_looop = df_rbh_km.copy()\n",
    "#only best hit\n",
    "df_looop = df_looop.sort_values('evalue').drop_duplicates(subset=['query'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b32865-53de-496a-a146-98e01e559eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF_TEST = df_looop[['PANTHER_kineto','PANTHER_model']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb19e4-044b-4927-830e-553eaf8f25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_looop = df_looop[(df_looop['fident'] > 0) & (df_looop['COV_query'] > 0) & (df_looop['COV_target'] > 0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091dfd9b-abc8-4079-9fdc-1a6be49b8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_looop[['PANTHER_kineto','PANTHER_model']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb106bc-9089-43c6-8b8f-d3716836e8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
