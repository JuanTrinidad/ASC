{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc265dea-a1aa-4a05-855c-5f7f676cedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c3e58d0-c8d0-4403-bab9-a4a899313404",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snakemake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/Disco9/jtrinidad/Doctorado_kinetoplastids_genome_annotation_orthologs/workflow/notebooks/007_polishing_pdbfiles_to_use_in_FATCAT.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B190.64.49.20/media/Disco9/jtrinidad/Doctorado_kinetoplastids_genome_annotation_orthologs/workflow/notebooks/007_polishing_pdbfiles_to_use_in_FATCAT.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m file1 \u001b[39m=\u001b[39m snakemake\u001b[39m.\u001b[39minput\u001b[39m.\u001b[39mfile1 \u001b[39m#'../report/TriTrypDB-65_All_species_clean_Ortholog_Group_Full_of_hypotetical_boolean.tsv'\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B190.64.49.20/media/Disco9/jtrinidad/Doctorado_kinetoplastids_genome_annotation_orthologs/workflow/notebooks/007_polishing_pdbfiles_to_use_in_FATCAT.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m file2 \u001b[39m=\u001b[39m snakemake\u001b[39m.\u001b[39minput\u001b[39m.\u001b[39mfile2 \u001b[39m#'../../results/reciprocal_best_hit_SingleOrgApproach_TSV/rbh_all_in_one_file.tsv'\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B190.64.49.20/media/Disco9/jtrinidad/Doctorado_kinetoplastids_genome_annotation_orthologs/workflow/notebooks/007_polishing_pdbfiles_to_use_in_FATCAT.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m file3 \u001b[39m=\u001b[39m snakemake\u001b[39m.\u001b[39minput\u001b[39m.\u001b[39mfile3 \u001b[39m#'../../results/Gene_annotation_info_from_uniprot_model_spp.tsv'\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snakemake' is not defined"
     ]
    }
   ],
   "source": [
    "file1 = snakemake.input.file1 #'../report/TriTrypDB-65_All_species_clean_Ortholog_Group_Full_of_hypotetical_boolean.tsv'\n",
    "file2 = snakemake.input.file2 #'../../results/reciprocal_best_hit_SingleOrgApproach_TSV/rbh_all_in_one_file.tsv'\n",
    "file3 = snakemake.input.file3 #'../../results/Gene_annotation_info_from_uniprot_model_spp.tsv'\n",
    "file4 = snakemake.input.file4 #'../report/TriTrypDB-65_All_species_clean_ortholog_groups_x_sequence_clustering_x_UNIPROT.tsv'\n",
    "outputfilepath = snakemake.output.list_file_to_fatcat\n",
    "outputfilepath2 = snakemake.output.tsv_to_match_pdbs_names\n",
    "\n",
    "# destination directory\n",
    "destination_dir = snakemake.params.destination_dir\n",
    "# cluster_structure_representers path\n",
    "cluster_str_rep_path = 'genome_data_sets/query_proteomes/pdb_files/cluster_structure_representers/'\n",
    "#path to model unziped\n",
    "path_to_model_unzip = 'genome_data_sets/subject_proteomes/pdb_files/model_organisms_files_unzip/'\n",
    "#cores\n",
    "num_cores = snakemake.threads\n",
    "#top hits\n",
    "top_hits = snakemake.params.top_hits\n",
    "#prefix added pdbs\n",
    "prefix = snakemake.params.prefix_of_added_pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file1 = '../report/TriTrypDB-65_All_species_clean_Ortholog_Group_Full_of_hypotetical_boolean.tsv'\n",
    "file2 = '../../results/reciprocal_best_hit_SingleOrgApproach_TSV/rbh_all_in_one_file.tsv'\n",
    "file3 = '../../results/Gene_annotation_info_from_uniprot_model_spp.tsv'\n",
    "file4 = '../report/TriTrypDB-65_All_species_clean_ortholog_groups_x_sequence_clustering_x_UNIPROT.tsv'\n",
    "\n",
    "outputfilepath = '../tmp/to_compare.list'\n",
    "outputfilepath2 = '../tmp/quert_taget_accesion_to_fatcat_list.tsv'\n",
    "\n",
    "# destination directory\n",
    "destination_dir = '../tmp/FATCAT_pdb_files/'\n",
    "# cluster_structure_representers path\n",
    "cluster_str_rep_path = '../genome_data_sets/query_proteomes/pdb_files/cluster_structure_representers/'\n",
    "#path to model unziped\n",
    "path_to_model_unzip = '../genome_data_sets/subject_proteomes/pdb_files/model_organisms_files_unzip/'\n",
    "#cores\n",
    "num_cores = 40\n",
    "#top hits\n",
    "top_hits = 5\n",
    "#prefix added pdbs\n",
    "prefix = 'wheelerlab_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab78670-2e8f-4472-a5eb-06fca60aba1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hypothetical OG data\n",
    "df_hypothetical_OG = pd.read_csv(file1, sep='\\t')\n",
    "\n",
    "#RBH results\n",
    "df_rbh = pd.read_csv(file2, sep='\\t', index_col=0)\n",
    "\n",
    "#model organims annotation data\n",
    "df_MO_annotation = pd.read_csv(file3, sep='\\t', low_memory=False, index_col=0)\n",
    "\n",
    "\n",
    "#estructure to genID to OG\n",
    "\n",
    "df_OG_genID_uniprot  = pd.read_csv(file4, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this are the db that i want to use as reference of annotation plus some usefull info. But removing not relevant columns for this analysis.\n",
    "columns_for_df =  ['Entry','Entry Name','Protein names', 'Organism', 'Organism (ID)', 'Proteomes','Taxonomic lineage' ,'EC number', 'Protein families', 'OrthoDB','PANTHER', 'InterPro', 'Pfam', 'eggNOG', 'Gene Ontology (cellular component)'] #'KEGG'\n",
    "\n",
    "\n",
    "#removing low annotation proteins from model org\n",
    "df_MO_annotation = df_MO_annotation[columns_for_df].dropna(thresh=10)\n",
    "\n",
    "#keeping only relevant columns\n",
    "#df_kineto_annotation = df_kineto_annotation[columns_for_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78edb28-eb7d-41c5-aaf8-884a60c811a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#aca uso inner porque quiero evitar las proteinas sin buena anotacion en el resultado\n",
    "df_rbh_km = df_rbh.merge(df_MO_annotation, left_on='target_uniprot_accession', right_on='Entry', how='left', suffixes=['_kineto', '_model'])\n",
    "#print(df_rbh_km.shape)\n",
    "\n",
    "\n",
    "# adding cluster representer\n",
    "df_rbh_km = df_rbh_km.merge(df_OG_genID_uniprot, left_on='query_uniprot_accession', right_on='uniprot', how='left')\n",
    "#print(df_rbh_km.shape)\n",
    "\n",
    "df_rbh_km = df_rbh_km.merge(df_hypothetical_OG, left_on='Ortholog_Group', right_on='cluster_representer_or_OG', how='left')\n",
    "#print(df_rbh_km.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a0f18-3e9e-4b81-aaf4-69c27fb7e6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794430d-5bb6-4a15-aa14-b28c74096a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70ae50d-ccf5-4a60-b470-994766a0f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbh_km = (\n",
    "    df_rbh_km\n",
    "    .sort_values('target', ascending=False)\n",
    "    .drop_duplicates(subset=['query_uniprot_accession', 'target_uniprot_accession']\n",
    "                    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c384e1-69b7-417c-ad23-6f545215aa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041439ec-8d5e-4eaf-a8e7-eacb40dc1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbh_km_tophits =(\n",
    "    df_rbh_km\n",
    "    .sort_values(['evalue'])\n",
    "    .groupby('query')\n",
    "    .head(top_hits)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31818fb2-7cce-4f3c-be95-fbfaf569345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a298c-6c8a-4218-ab46-0da82888d189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85acd595-e275-4d07-939b-18dea662196f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#simplifiying names of pdb files\n",
    "df_rbh_km_tophits['new_simple_name'] =  (\n",
    "\n",
    "    df_rbh_km_tophits['query_uniprot_accession']\n",
    "    .str.replace(prefix,'')\n",
    "    .str.split('_', expand=True)[0]\n",
    "    .str.replace('.','')\n",
    "    + '.pdb'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#dropping duplicates\n",
    "df_rbh_km_tophits_to_move_files = df_rbh_km_tophits[['query', 'query_uniprot_accession', 'new_simple_name']].drop_duplicates()\n",
    "#adding path to file\n",
    "df_rbh_km_tophits_to_move_files['path_to_file'] = cluster_str_rep_path + df_rbh_km_tophits_to_move_files['query']\n",
    "#creating the list of tuples\n",
    "files_list = list(zip(df_rbh_km_tophits_to_move_files.path_to_file, df_rbh_km_tophits_to_move_files.new_simple_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042269a-88a1-4541-a9df-566e691aa32d",
   "metadata": {},
   "source": [
    "#### Funtion to copie pdb files from cluster structure representer to use FATCAT. Also name simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4197aee4-8192-439e-80de-743f78876307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "\n",
    "def copy_file(file, destination_dir):\n",
    "    \"\"\"Copy a file to a destination directory.\"\"\"\n",
    "    file_path, new_name = file\n",
    "    shutil.copy(file_path, os.path.join(destination_dir, new_name))\n",
    "\n",
    "\n",
    "def copy_files(files, destination_dir, num_cores=4):\n",
    "    \"\"\"Copy a list of files to a destination directory in parallel.\"\"\"\n",
    "    if os.path.exists(destination_dir):\n",
    "        shutil.rmtree(destination_dir)\n",
    "    os.makedirs(destination_dir)\n",
    "    with multiprocessing.Pool(num_cores) as pool:\n",
    "        pool.starmap(copy_file, [(file, destination_dir) for file in files])\n",
    "\n",
    "def copy_files_wo_rm(files, destination_dir, num_cores=4):\n",
    "    \"\"\"Copy a list of files to a destination directory in parallel.\"\"\"\n",
    "    with multiprocessing.Pool(num_cores) as pool:\n",
    "        pool.starmap(copy_file, [(file, destination_dir) for file in files])\n",
    "\n",
    "\n",
    "\n",
    "# copy the files to the destination directory in parallel\n",
    "copy_files(files_list, destination_dir, num_cores= num_cores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f88530-7c5d-4b59-a092-3cea447a37c2",
   "metadata": {},
   "source": [
    "#### same approach to model org files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, proteome, path):\n",
    "    df = df[df.proteome == proteome]\n",
    "    df = df.drop_duplicates(subset=['target'])\n",
    "    df['path_to_file'] = path + df['target'] \n",
    "    df['new_simple_name'] = df.target.str.split('-',expand=True)[1]  +  df.target.str[-8:]\n",
    "\n",
    "\n",
    "    return list(zip(df.path_to_file, df.new_simple_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coping files from UP000018087_1391915_SPOS1_v4 to FACTCAT_folder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coping files from UP000001450_36329_PLAF7_v4 to FACTCAT_folder\n",
      "Coping files from UP000001631_447093_AJECG_v4 to FACTCAT_folder\n",
      "Coping files from UP000001014_99287_SALTY_v4 to FACTCAT_folder\n",
      "Coping files from UP000000589_10090_MOUSE_v4 to FACTCAT_folder\n",
      "Coping files from UP000002059_502779_PARBA_v4 to FACTCAT_folder\n",
      "Coping files from UP000008827_3847_SOYBN_v4 to FACTCAT_folder\n",
      "Coping files from UP000059680_39947_ORYSJ_v4 to FACTCAT_folder\n",
      "Coping files from UP000001584_83332_MYCTU_v4 to FACTCAT_folder\n",
      "Coping files from UP000000625_83333_ECOLI_v4 to FACTCAT_folder\n",
      "Coping files from UP000000429_85962_HELPY_v4 to FACTCAT_folder\n",
      "Coping files from UP000270924_6293_WUCBA_v4 to FACTCAT_folder\n",
      "Coping files from UP000000437_7955_DANRE_v4 to FACTCAT_folder\n",
      "Coping files from UP000002195_44689_DICDI_v4 to FACTCAT_folder\n",
      "Coping files from UP000006304_1133849_9NOCA1_v4 to FACTCAT_folder\n",
      "Coping files from UP000000586_171101_STRR6_v4 to FACTCAT_folder\n",
      "Coping files from UP000000805_243232_METJA_v4 to FACTCAT_folder\n",
      "Coping files from UP000020681_1299332_MYCUL_v4 to FACTCAT_folder\n",
      "Coping files from UP000053029_1442368_9EURO2_v4 to FACTCAT_folder\n",
      "Coping files from UP000002311_559292_YEAST_v4 to FACTCAT_folder\n",
      "Coping files from UP000000806_272631_MYCLE_v4 to FACTCAT_folder\n",
      "Coping files from UP000000803_7227_DROME_v4 to FACTCAT_folder\n",
      "Coping files from UP000002485_284812_SCHPO_v4 to FACTCAT_folder\n",
      "Coping files from UP000024404_6282_ONCVO_v4 to FACTCAT_folder\n",
      "Coping files from UP000005640_9606_HUMAN_v4 to FACTCAT_folder\n",
      "Coping files from UP000008816_93061_STAA8_v4 to FACTCAT_folder\n",
      "Coping files from UP000030665_36087_TRITR_v4 to FACTCAT_folder\n",
      "Coping files from UP000274756_318479_DRAME_v4 to FACTCAT_folder\n",
      "Coping files from UP000000559_237561_CANAL_v4 to FACTCAT_folder\n",
      "Coping files from UP000094526_86049_9EURO1_v4 to FACTCAT_folder\n",
      "Coping files from UP000078237_100816_9PEZI1_v4 to FACTCAT_folder\n",
      "Coping files from UP000006548_3702_ARATH_v4 to FACTCAT_folder\n",
      "Coping files from UP000325664_1352_ENTFC_v4 to FACTCAT_folder\n",
      "Coping files from UP000008854_6183_SCHMA_v4 to FACTCAT_folder\n",
      "Coping files from UP000006672_6279_BRUMA_v4 to FACTCAT_folder\n",
      "Coping files from UP000002716_300267_SHIDS_v4 to FACTCAT_folder\n",
      "Coping files from UP000000535_242231_NEIG1_v4 to FACTCAT_folder\n",
      "Coping files from UP000000799_192222_CAMJE_v4 to FACTCAT_folder\n",
      "Coping files from UP000007305_4577_MAIZE_v4 to FACTCAT_folder\n",
      "Coping files from UP000001940_6239_CAEEL_v4 to FACTCAT_folder\n",
      "Coping files from UP000000579_71421_HAEIN_v4 to FACTCAT_folder\n",
      "Coping files from UP000035681_6248_STRER_v4 to FACTCAT_folder\n",
      "Coping files from UP000007841_1125630_KLEPH_v4 to FACTCAT_folder\n",
      "Coping files from UP000002438_208964_PSEAE_v4 to FACTCAT_folder\n",
      "Coping files from UP000002494_10116_RAT_v4 to FACTCAT_folder\n"
     ]
    }
   ],
   "source": [
    "for proteome in os.listdir(path_to_model_unzip):\n",
    "    UPproteome = proteome.split('_')[0]\n",
    "    \n",
    "    if UPproteome in df_rbh_km_tophits['proteome'].unique():\n",
    "        print(f'Coping files from {proteome} to FACTCAT_folder')\n",
    "\n",
    "        path = path_to_model_unzip + proteome + '/'\n",
    "        \n",
    "        files_list = filter_df(df_rbh_km_tophits, UPproteome, path)\n",
    "        \n",
    "        copy_files_wo_rm(files_list, destination_dir, num_cores= num_cores)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final output list of files to compare with FATCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_file_for_FATCATQue(df, outputfilepath, outputfilepath2):\n",
    "    df['new_simple_name'] = df['new_simple_name'].str.split('.', expand=True)[0]\n",
    "    df.sort_values('new_simple_name', inplace=True)\n",
    "\n",
    "    df[['new_simple_name', 'target_uniprot_accession']].to_csv(outputfilepath, sep=' ', header=False, index=False) \n",
    "    df[['query','target', 'new_simple_name', 'target_uniprot_accession']].to_csv(outputfilepath2, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "creating_file_for_FATCATQue(df_rbh_km_tophits, outputfilepath, outputfilepath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
