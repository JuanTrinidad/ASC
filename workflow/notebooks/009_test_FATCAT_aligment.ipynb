{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import glob\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = \"tmp/FATCAT_aligments/\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if os.path.exists(folder_path):\n",
    "    # Remove the folder and its contents\n",
    "    shutil.rmtree(folder_path)\n",
    "    \n",
    "# Create the folder\n",
    "os.makedirs(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = snakemake.threads # Specify the number of cores to use\n",
    "\n",
    "df = pd.read_csv(snakemake.input[0], sep='\\t') #'../tmp/TriTrypDB-65_All_species_clean_query_taget_accesion_to_fatcat_list.tsv'\n",
    "\n",
    "original_shape = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to ensure that we will continue with pdb files that are in the correct folder.\n",
    "uniprot_names = []\n",
    "for file in glob.glob('tmp/FATCAT_pdb_files/*.pdb'):\n",
    "\n",
    "    uniprot = file.split('/')[-1][:-4]\n",
    "\n",
    "    uniprot_names.append(uniprot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the uniprot names are in the dataframe\n",
    "df = (\n",
    "df[\n",
    "    df['query_uniprot_accession'].isin(uniprot_names) &\n",
    "    df['target_uniprot_accession'].isin(uniprot_names)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 .pdb files are not present in the FATCAT folder. Probably their are not in AFDB with the same UNIPROT accession than in the model organisms proteome files. Please check. The script will continue with the files that are present.\n"
     ]
    }
   ],
   "source": [
    "#checking if the number of rows is the same as the original dataframe\n",
    "if original_shape == df.shape:\n",
    "    print('All of the .pdb files are present in the FATCAT folder.')\n",
    "else:\n",
    "    pdb_not_present = original_shape[0] - df.shape[0]\n",
    "    print(f'{pdb_not_present} .pdb files are not present in the FATCAT folder. Probably their are not in AFDB with the same UNIPROT accession than in the model organisms proteome files. Please check. The script will continue with the files that are present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_args = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    pdb1 = row['target_uniprot_accession']\n",
    "    pdb2 = row['query_uniprot_accession'] \n",
    "\n",
    "    command_args.append([\"git_repo_cloned/FATCAT/FATCATMain/FATCAT\", \n",
    "                         \"-p1\", f\"tmp/FATCAT_pdb_files/{pdb1}.pdb\",\n",
    "                         \"-p2\", f\"tmp/FATCAT_pdb_files/{pdb2}.pdb\",\n",
    "                         \"-o\", f\"tmp/FATCAT_aligments/{pdb1}_{pdb2}\", \n",
    "                         \"-m\", \"-t\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_command(args):\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(args, capture_output=True, text=True, check=True)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "            \n",
    "    #except subprocess.CalledProcessError as e:\n",
    "\n",
    "    #    if len(e.stdout) != 0:\n",
    "    #        print(f\"No output for {args[2]} vs {args[4]} comparison by FATCAT.\\n\")\n",
    "    #        print(\"Output:\")\n",
    "    #        print(result.stdout)\n",
    "\n",
    "        \n",
    "\n",
    "# Run the commands in parallel using multiple cores\n",
    "with multiprocessing.Pool(num_cores) as pool:\n",
    "    \n",
    "    pool.map(run_command, command_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def run_command(args):\n",
    "    result = None  # Initialize result\n",
    "    try:\n",
    "        result = subprocess.run(args, capture_output=True, text=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed: {e}\")\n",
    "        if result:  # Check if result was assigned\n",
    "            print(result.stdout)\n",
    "    return result\n",
    "\n",
    "# Run the commands in parallel using multiple cores\n",
    "with multiprocessing.Pool(num_cores) as pool:\n",
    "    pool.map(run_command, command_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
